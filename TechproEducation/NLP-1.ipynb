{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-11-22-01-03-29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Vectorization For NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-11-22-01-04-41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Awesome!!!, This is fantastic!!!. We are very pleased...3456\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize , sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token = word_tokenize(sample_text.lower())\n",
    "sent_token = sent_tokenize(sample_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'fantastic',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " '.',\n",
       " 'we',\n",
       " 'are',\n",
       " 'very',\n",
       " 'pleased',\n",
       " '...',\n",
       " '3456']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome!!', '!, this is fantastic!!!.', 'we are very pleased...3456']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Punctuation and Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome', 'this', 'is', 'fantastic', 'we', 'are', 'very', 'pleased']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_without_punc = [w for w in word_token if w.isalpha()] # .isal() for only alphabetics. # .isalnum() for number and object \n",
    "tokens_without_punc  # If you want to keep numbers, you should use .isalnum() rather than isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome', 'this', 'is', 'fantastic', 'we', 'are', 'very', 'pleased', '3456']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_without_punc = [w for w in word_token if w.isalnum()]\n",
    "tokens_without_punc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-11-22-01-18-33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words('english') # Our all stopwords.\n",
    "print(stop_words)\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha', 'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani']\n",
      "53\n"
     ]
    }
   ],
   "source": [
    "stop_words2 = stopwords.words('turkish') # Our all stopwords.\n",
    "print(stop_words2)\n",
    "print(len(stop_words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome', 'this', 'is', 'fantastic', 'we', 'are', 'very', 'pleased', '3456']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_without_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome', 'fantastic', 'pleased', '3456']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_without_sw = [w for w in tokens_without_punc if w not in stop_words]# if you make a sentiment analysis , you can't remove \n",
    "                                                                           # negative auxiliary verb\n",
    "tokens_without_sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-11-22-01-39-47.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization-Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'child'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer().lemmatize(\"children\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordNetLemmatizer().lemmatize(\"runs\" , pos = 'n')  # 'v' mean verbs. n mean nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesome', 'fantastic', 'pleased', '3456']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem = [WordNetLemmatizer().lemmatize(t) for t in tokens_without_sw]\n",
    "lem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-11-22-01-57-41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization-Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'develop'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer().stem('development')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awesom', 'fantast', 'pleas', '3456']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem = [PorterStemmer().stem(t) for t in tokens_without_sw]\n",
    "stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'awesome fantastic pleased 3456'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Function - for classification (NOT for sentiment analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(data):\n",
    "    \n",
    "    #1. Tokenize\n",
    "    text_tokens = word_tokenize(data.lower()) \n",
    "    \n",
    "    #2. Remove Puncs\n",
    "    tokens_without_punc = [w for w in text_tokens if w.isalpha()]\n",
    "    \n",
    "    #3. Removing Stopwords\n",
    "    tokens_without_sw = [t for t in tokens_without_punc if t not in stop_words]\n",
    "    \n",
    "    #4. lemma\n",
    "    text_cleaned = [WordNetLemmatizer().lemmatize(t) for t in tokens_without_sw]\n",
    "    \n",
    "    #joining\n",
    "    return \" \".join(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    awesome fantastic pleased\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(sample_text).apply(cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Function - for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text= \"Awesome!!!, This is fantastic!!!. We are very pleased...3456. don't eat, isn't. no problem for me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Awesome',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " ',',\n",
       " 'This',\n",
       " 'is',\n",
       " 'fantastic',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " '.',\n",
       " 'We',\n",
       " 'are',\n",
       " 'very',\n",
       " 'pleased',\n",
       " '...',\n",
       " '3456.',\n",
       " 'dont',\n",
       " 'eat',\n",
       " ',',\n",
       " 'isnt',\n",
       " '.',\n",
       " 'no',\n",
       " 'problem',\n",
       " 'for',\n",
       " 'me']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = sample_text.replace(\"'\",'')\n",
    "word = word_tokenize(s)\n",
    "word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stopwords\n",
    "for i in [\"not\", \"no\"]:\n",
    "    stop_words.remove(i)\n",
    "\n",
    "def cleaning_fsa(data):\n",
    "    \n",
    "    \n",
    "    #1. removing upper brackets to keep negative auxiliary verbs in text\n",
    "    text = data.replace(\"'\",'')\n",
    "         \n",
    "    #2. Tokenize\n",
    "    text_tokens = word_tokenize(text.lower()) \n",
    "    \n",
    "    #3. Remove numbers\n",
    "    tokens_without_punc = [w for w in text_tokens if w.isalpha()]\n",
    "    \n",
    "    \n",
    "        \n",
    "    tokens_without_sw = [t for t in tokens_without_punc if t not in stop_words]\n",
    "    \n",
    "    #4. lemma\n",
    "    text_cleaned = [WordNetLemmatizer().lemmatize(t) for t in tokens_without_sw]\n",
    "    \n",
    "    #joining\n",
    "    return \" \".join(text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'nor',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    awesome fantastic pleased dont eat isnt no pro...\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(sample_text).apply(cleaning_fsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorization and TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"airline_tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0               neutral                @VirginAmerica What @dhepburn said.\n",
       "1              positive  @VirginAmerica plus you've added commercials t...\n",
       "2               neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3              negative  @VirginAmerica it's really aggressive to blast...\n",
       "4              negative  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635          positive  @AmericanAir thank you we got on a different f...\n",
       "14636          negative  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637           neutral  @AmericanAir Please bring American Airlines to...\n",
       "14638          negative  @AmericanAir you have my money, you change my ...\n",
       "14639           neutral  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['airline_sentiment','text']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing...\n",
       "5          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
       "6          positive  @VirginAmerica yes, nearly every time I fly VX...\n",
       "7           neutral  @VirginAmerica Really missed a prime opportuni..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>virginamerica plus added commercial experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica today must mean need take anothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>virginamerica seriously would pay flight seat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>virginamerica yes nearly every time fly vx ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neutral</td>\n",
       "      <td>virginamerica really missed prime opportunity ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                        virginamerica dhepburn said\n",
       "1          positive  virginamerica plus added commercial experience...\n",
       "2           neutral  virginamerica today must mean need take anothe...\n",
       "3          negative  virginamerica really aggressive blast obnoxiou...\n",
       "4          negative                 virginamerica really big bad thing\n",
       "5          negative  virginamerica seriously would pay flight seat ...\n",
       "6          positive  virginamerica yes nearly every time fly vx ear...\n",
       "7           neutral  virginamerica really missed prime opportunity ..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\"text\"] = df2[\"text\"].apply(cleaning)\n",
    "df2.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-11-22-02-08-45.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[\"text\"]\n",
    "y = df2[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, stratify = y, random_state = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_count = vectorizer.fit_transform(X_train)   # Only fitting with X_train as we do at fitting scaler.\n",
    "X_test_count = vectorizer.transform(X_test)     # If the word in X test is not in X train, it is ignored.\n",
    "# That's why its needs to train in the big Corpus so that we can get good results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaaand', 'aaadvantage', ..., 'zrh', 'zukes', 'zurich'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaadvantage</th>\n",
       "      <th>aaalwayslate</th>\n",
       "      <th>aacustomerservice</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>aafail</th>\n",
       "      <th>aaron</th>\n",
       "      <th>...</th>\n",
       "      <th>yyz</th>\n",
       "      <th>zabsonre</th>\n",
       "      <th>zambia</th>\n",
       "      <th>zero</th>\n",
       "      <th>zfv</th>\n",
       "      <th>zkatcher</th>\n",
       "      <th>zone</th>\n",
       "      <th>zrh</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7315</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7316</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7317</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7320 rows × 7300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaaand  aaadvantage  aaalwayslate  aacustomerservice  aadavantage  \\\n",
       "0      0       0            0             0                  0            0   \n",
       "1      0       0            0             0                  0            0   \n",
       "2      0       0            0             0                  0            0   \n",
       "3      0       0            0             0                  0            0   \n",
       "4      0       0            0             0                  0            0   \n",
       "...   ..     ...          ...           ...                ...          ...   \n",
       "7315   0       0            0             0                  0            0   \n",
       "7316   0       0            0             0                  0            0   \n",
       "7317   0       0            0             0                  0            0   \n",
       "7318   0       0            0             0                  0            0   \n",
       "7319   0       0            0             0                  0            0   \n",
       "\n",
       "      aadv  aadvantage  aafail  aaron  ...  yyz  zabsonre  zambia  zero  zfv  \\\n",
       "0        0           0       0      0  ...    0         0       0     0    0   \n",
       "1        0           0       0      0  ...    0         0       0     0    0   \n",
       "2        0           0       0      0  ...    0         0       0     0    0   \n",
       "3        0           0       0      0  ...    0         0       0     0    0   \n",
       "4        0           0       0      0  ...    0         0       0     0    0   \n",
       "...    ...         ...     ...    ...  ...  ...       ...     ...   ...  ...   \n",
       "7315     0           0       0      0  ...    0         0       0     0    0   \n",
       "7316     0           0       0      0  ...    0         0       0     0    0   \n",
       "7317     0           0       0      0  ...    0         0       0     0    0   \n",
       "7318     0           0       0      0  ...    0         0       0     0    0   \n",
       "7319     0           0       0      0  ...    0         0       0     0    0   \n",
       "\n",
       "      zkatcher  zone  zrh  zukes  zurich  \n",
       "0            0     0    0      0       0  \n",
       "1            0     0    0      0       0  \n",
       "2            0     0    0      0       0  \n",
       "3            0     0    0      0       0  \n",
       "4            0     0    0      0       0  \n",
       "...        ...   ...  ...    ...     ...  \n",
       "7315         0     0    0      0       0  \n",
       "7316         0     0    0      0       0  \n",
       "7317         0     0    0      0       0  \n",
       "7318         0     0    0      0       0  \n",
       "7319         0     0    0      0       0  \n",
       "\n",
       "[7320 rows x 7300 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_count = pd.DataFrame(X_train_count.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2316                united also checked email file correct\n",
       "2648     united hear guitar damaged december use guitar...\n",
       "12396                     americanair yes bit follow ca dm\n",
       "7186     jetblue believe irina super disappointed eatup...\n",
       "13875    americanair seriously not want wait hour fligh...\n",
       "                               ...                        \n",
       "5056     southwestair give info flt bdl see cancelled f...\n",
       "3710     united think guy half full flight held overboo...\n",
       "5544                  southwestair got taken care thank lt\n",
       "13638    americanair visiting sju returning paris check...\n",
       "7421     jetblue domestic clear not sit lovely terminal...\n",
       "Name: text, Length: 7320, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica seriously would pay flight seat playing really bad thing flying va'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'united': 6782,\n",
       " 'also': 210,\n",
       " 'checked': 1064,\n",
       " 'email': 2039,\n",
       " 'file': 2382,\n",
       " 'correct': 1393,\n",
       " 'hear': 2945,\n",
       " 'guitar': 2852,\n",
       " 'damaged': 1562,\n",
       " 'december': 1609,\n",
       " 'use': 6878,\n",
       " 'earn': 1974,\n",
       " 'living': 3750,\n",
       " 'get': 2701,\n",
       " 'act': 66,\n",
       " 'together': 6543,\n",
       " 'americanair': 234,\n",
       " 'yes': 7258,\n",
       " 'bit': 678,\n",
       " 'follow': 2512,\n",
       " 'ca': 892,\n",
       " 'dm': 1853,\n",
       " 'jetblue': 3446,\n",
       " 'believe': 619,\n",
       " 'irina': 3376,\n",
       " 'super': 6231,\n",
       " 'disappointed': 1784,\n",
       " 'eatup': 1992,\n",
       " 'cafe': 900,\n",
       " 'available': 472,\n",
       " 'bos': 754,\n",
       " 'gt': 2838,\n",
       " 'sfo': 5738,\n",
       " 'flight': 2442,\n",
       " 'today': 6541,\n",
       " 'seriously': 5716,\n",
       " 'not': 4362,\n",
       " 'want': 7016,\n",
       " 'wait': 6991,\n",
       " 'hour': 3090,\n",
       " 'prepare': 4939,\n",
       " 'family': 2308,\n",
       " 'funeral': 2642,\n",
       " 'usairways': 6865,\n",
       " 'worst': 7189,\n",
       " 'airline': 150,\n",
       " 'alfamilyoffour': 182,\n",
       " 'maybe': 3958,\n",
       " 'anyone': 300,\n",
       " 'answering': 288,\n",
       " 'phone': 4750,\n",
       " 'would': 7201,\n",
       " 'please': 4818,\n",
       " 'call': 910,\n",
       " 'back': 512,\n",
       " 'late': 3627,\n",
       " 'flightr': 2463,\n",
       " 'good': 2763,\n",
       " 'enough': 2090,\n",
       " 'made': 3864,\n",
       " 'miss': 4093,\n",
       " 'first': 2410,\n",
       " 'class': 1136,\n",
       " 'even': 2159,\n",
       " 'enter': 2096,\n",
       " 'admiral': 90,\n",
       " 'club': 1173,\n",
       " 'happy': 2896,\n",
       " 'fix': 2418,\n",
       " 'show': 5798,\n",
       " 'seat': 5652,\n",
       " 'need': 4237,\n",
       " 'honor': 3050,\n",
       " 'shouldnt': 5795,\n",
       " 'spend': 6032,\n",
       " 'really': 5175,\n",
       " 'someone': 5967,\n",
       " 'assist': 411,\n",
       " 'waiting': 6994,\n",
       " 'twitter': 6700,\n",
       " 'virginamerica': 6963,\n",
       " 'got': 2776,\n",
       " 'squared': 6066,\n",
       " 'away': 493,\n",
       " 'picked': 4762,\n",
       " 'soon': 5976,\n",
       " 'tweeted': 6693,\n",
       " 'sooner': 5977,\n",
       " 'southwestair': 6001,\n",
       " 'writing': 7217,\n",
       " 'service': 5721,\n",
       " 'via': 6942,\n",
       " 'company': 1255,\n",
       " 'transport': 6611,\n",
       " 'well': 7072,\n",
       " 'client': 1156,\n",
       " 'monthly': 4139,\n",
       " 'sw': 6267,\n",
       " 'cancelled': 923,\n",
       " 'wanted': 7018,\n",
       " 'take': 6323,\n",
       " 'keep': 3530,\n",
       " 'price': 4963,\n",
       " 'held': 2961,\n",
       " 'june': 3514,\n",
       " 'yet': 7261,\n",
       " 'put': 5080,\n",
       " 'russell': 5531,\n",
       " 'daiber': 1554,\n",
       " 'ticket': 6496,\n",
       " 'premium': 4936,\n",
       " 'eco': 1998,\n",
       " 'appreciated': 330,\n",
       " 'trying': 6667,\n",
       " 'change': 1028,\n",
       " 'reservation': 5367,\n",
       " 'hanging': 2885,\n",
       " 'frustrating': 2614,\n",
       " 'paid': 4599,\n",
       " 'refund': 5247,\n",
       " 'book': 741,\n",
       " 'award': 491,\n",
       " 'september': 5712,\n",
       " 'aegeanairlines': 106,\n",
       " 'many': 3914,\n",
       " 'availab': 470,\n",
       " 'sev': 5729,\n",
       " 'ppl': 4895,\n",
       " 'im': 3177,\n",
       " 'office': 4441,\n",
       " 'received': 5191,\n",
       " 'apology': 310,\n",
       " 'ff': 2366,\n",
       " 'mile': 4060,\n",
       " 'delay': 1638,\n",
       " 'apologize': 308,\n",
       " 'select': 5683,\n",
       " 'nothing': 4373,\n",
       " 'icloud': 3141,\n",
       " 'help': 2967,\n",
       " 'according': 48,\n",
       " 'jfk': 3465,\n",
       " 'plenty': 4830,\n",
       " 'plane': 4797,\n",
       " 'landing': 3612,\n",
       " 'no': 4298,\n",
       " 'problem': 4988,\n",
       " 'air': 144,\n",
       " 'traffic': 6595,\n",
       " 'crew': 1472,\n",
       " 'could': 1409,\n",
       " 'shit': 5771,\n",
       " 'one': 4469,\n",
       " 'notice': 4374,\n",
       " 'rudeness': 5516,\n",
       " 'ground': 2825,\n",
       " 'staff': 6073,\n",
       " 'faa': 2278,\n",
       " 'guideline': 2849,\n",
       " 'regarding': 5256,\n",
       " 'bumping': 861,\n",
       " 'acceptable': 32,\n",
       " 'give': 2727,\n",
       " 'voucher': 6981,\n",
       " 'fare': 2314,\n",
       " 'cab': 893,\n",
       " 'ride': 5438,\n",
       " 'dfw': 1730,\n",
       " 'love': 3820,\n",
       " 'bag': 535,\n",
       " 'reimburse': 5268,\n",
       " 'thank': 6410,\n",
       " 'much': 4179,\n",
       " 'mac': 3861,\n",
       " 'computer': 1287,\n",
       " 'left': 3665,\n",
       " 'bwi': 887,\n",
       " 'la': 3594,\n",
       " 'reward': 5429,\n",
       " 'recovery': 5211,\n",
       " 'info': 3274,\n",
       " 'important': 3195,\n",
       " 'passenger': 4649,\n",
       " 'honesty': 3047,\n",
       " 'agent': 125,\n",
       " 'wo': 7160,\n",
       " 'hold': 3030,\n",
       " 'connection': 1321,\n",
       " 'arriving': 379,\n",
       " 'min': 4068,\n",
       " 'departure': 1675,\n",
       " 'time': 6510,\n",
       " 'flt': 2478,\n",
       " 'gate': 2676,\n",
       " 'day': 1583,\n",
       " 'fly': 2481,\n",
       " 'two': 6703,\n",
       " 'delayed': 1639,\n",
       " 'still': 6125,\n",
       " 'ewr': 2183,\n",
       " 'interaction': 3334,\n",
       " 'people': 4704,\n",
       " 'morning': 4146,\n",
       " 'bad': 523,\n",
       " 'weather': 7050,\n",
       " 'sorry': 5985,\n",
       " 'wont': 7169,\n",
       " 'flying': 2490,\n",
       " 'kind': 3554,\n",
       " 'hardworking': 2910,\n",
       " 'infrastructure': 3282,\n",
       " 'given': 2728,\n",
       " 'horrid': 3076,\n",
       " 'massivefail': 3944,\n",
       " 'failphone': 2292,\n",
       " 'fail': 2286,\n",
       " 'empathizes': 2058,\n",
       " 'disappointment': 1786,\n",
       " 'entertainmnt': 2103,\n",
       " 'worth': 7199,\n",
       " 'unfriendlyskies': 6772,\n",
       " 'http': 3104,\n",
       " 'travisamex': 6628,\n",
       " 'gross': 2821,\n",
       " 'incompetence': 3229,\n",
       " 'understaffing': 6749,\n",
       " 'forgetting': 2534,\n",
       " 'load': 3758,\n",
       " 'duck': 1944,\n",
       " 'truth': 6661,\n",
       " 'must': 4190,\n",
       " 'heard': 2946,\n",
       " 'wrong': 7219,\n",
       " 'sweet': 6280,\n",
       " 'mixtape': 4112,\n",
       " 'though': 6468,\n",
       " 'record': 5206,\n",
       " 'leave': 3661,\n",
       " 'done': 1878,\n",
       " 'ua': 6714,\n",
       " 'copilot': 1384,\n",
       " 'raleigh': 5125,\n",
       " 'disappointing': 1785,\n",
       " 'hrl': 3101,\n",
       " 'limited': 3720,\n",
       " 'route': 5496,\n",
       " 'sitting': 5855,\n",
       " 'talking': 6333,\n",
       " 'tech': 6364,\n",
       " 'conference': 1300,\n",
       " 'awesome': 495,\n",
       " 'guy': 2856,\n",
       " 'rolled': 5484,\n",
       " 'across': 65,\n",
       " 'luv': 3850,\n",
       " 'lol': 3786,\n",
       " 'go': 2744,\n",
       " 'cleveland': 1151,\n",
       " 'instead': 3313,\n",
       " 'huge': 3108,\n",
       " 'thanks': 6417,\n",
       " 'flew': 2434,\n",
       " 'dca': 1590,\n",
       " 'sju': 5864,\n",
       " 'monday': 4130,\n",
       " 'night': 4289,\n",
       " 'snow': 5936,\n",
       " 'reference': 5232,\n",
       " 'id': 3145,\n",
       " 'number': 4399,\n",
       " 'looking': 3797,\n",
       " 'poor': 4860,\n",
       " 'experience': 2241,\n",
       " 'malfunction': 3893,\n",
       " 'stuck': 6183,\n",
       " 'missing': 4099,\n",
       " 'meeting': 3994,\n",
       " 'san': 5565,\n",
       " 'diego': 1745,\n",
       " 'home': 3039,\n",
       " 'telling': 6378,\n",
       " 'compensation': 1265,\n",
       " 'anything': 301,\n",
       " 'income': 3227,\n",
       " 'fll': 2470,\n",
       " 'hotel': 3085,\n",
       " 'necessary': 4235,\n",
       " 'remember': 5300,\n",
       " 'business': 873,\n",
       " 'pleasant': 4816,\n",
       " 'mean': 3971,\n",
       " 'tell': 6376,\n",
       " 'friend': 2591,\n",
       " 'everyone': 2171,\n",
       " 'see': 5672,\n",
       " 'ever': 2167,\n",
       " 'lost': 3809,\n",
       " 'luggage': 3843,\n",
       " 'infant': 3265,\n",
       " 'year': 7250,\n",
       " 'old': 4461,\n",
       " 'customer': 1525,\n",
       " 'never': 4259,\n",
       " 'answered': 287,\n",
       " 'tried': 6639,\n",
       " 'philadelphia': 4740,\n",
       " 'minute': 4077,\n",
       " 'great': 2802,\n",
       " 'new': 4266,\n",
       " 'logo': 3784,\n",
       " 'going': 2752,\n",
       " 'look': 3793,\n",
       " 'amazing': 226,\n",
       " 'airplane': 154,\n",
       " 'pilot': 4772,\n",
       " 'another': 284,\n",
       " 'attendant': 441,\n",
       " 'walking': 7007,\n",
       " 'laughing': 3635,\n",
       " 'wow': 7207,\n",
       " 'flightled': 2457,\n",
       " 'lga': 3689,\n",
       " 'delta': 1654,\n",
       " 'took': 6561,\n",
       " 'like': 3708,\n",
       " 'carrier': 960,\n",
       " 'pls': 4835,\n",
       " 'sure': 6247,\n",
       " 'ots': 4534,\n",
       " 'pant': 4615,\n",
       " 'lot': 3815,\n",
       " 'cranky': 1450,\n",
       " 'line': 3724,\n",
       " 'cmh': 1178,\n",
       " 'reflight': 5236,\n",
       " 'booking': 743,\n",
       " 'delaying': 1641,\n",
       " 'direct': 1767,\n",
       " 'flyer': 2485,\n",
       " 'next': 4275,\n",
       " 'free': 2575,\n",
       " 'cocktail': 1193,\n",
       " 'denver': 1666,\n",
       " 'rock': 5476,\n",
       " 'open': 4491,\n",
       " 'letter': 3684,\n",
       " 'lt': 3836,\n",
       " 'child': 1085,\n",
       " 'inspired': 3308,\n",
       " 'incredible': 3240,\n",
       " 'svc': 6265,\n",
       " 'mint': 4075,\n",
       " 'magic': 3871,\n",
       " 'dfwairport': 1731,\n",
       " 'listening': 3737,\n",
       " 'taking': 6328,\n",
       " 'house': 3092,\n",
       " 'kicking': 3543,\n",
       " 'tomorrow': 6553,\n",
       " 'iceday': 3138,\n",
       " 'find': 2396,\n",
       " 'ny': 4409,\n",
       " 'scheduled': 5616,\n",
       " 'checking': 1067,\n",
       " 'okay': 4456,\n",
       " 'stranded': 6156,\n",
       " 'blame': 693,\n",
       " 'speak': 6017,\n",
       " 'understand': 6750,\n",
       " 'concept': 1289,\n",
       " 'zone': 7296,\n",
       " 'hand': 2871,\n",
       " 'experienced': 2242,\n",
       " 'make': 3883,\n",
       " 'comcast': 1223,\n",
       " 'unitedairlines': 6784,\n",
       " 'giving': 2729,\n",
       " 'cot': 1406,\n",
       " 'room': 5489,\n",
       " 'terrible': 6391,\n",
       " 'mom': 4124,\n",
       " 'always': 218,\n",
       " 'said': 5554,\n",
       " 'settle': 5727,\n",
       " 'chip': 1092,\n",
       " 'ai': 141,\n",
       " 'blue': 717,\n",
       " 'accordingly': 49,\n",
       " 'dont': 1881,\n",
       " 'respond': 5380,\n",
       " 'figured': 2381,\n",
       " 'listed': 3735,\n",
       " 'almost': 203,\n",
       " 'hr': 3100,\n",
       " 'cheer': 1069,\n",
       " 'karen': 3523,\n",
       " 'riedel': 5442,\n",
       " 'star': 6084,\n",
       " 'employee': 2061,\n",
       " 'miracle': 4078,\n",
       " 'worker': 7179,\n",
       " 'thought': 6469,\n",
       " 'smooth': 5918,\n",
       " 'nicely': 4284,\n",
       " 'flighted': 2450,\n",
       " 'tonight': 6558,\n",
       " 'auto': 464,\n",
       " 'rebooked': 5184,\n",
       " 'tuesday': 6679,\n",
       " 'work': 7176,\n",
       " 'showing': 5800,\n",
       " 'departed': 1671,\n",
       " 'bought': 765,\n",
       " 'published': 5059,\n",
       " 'mistake': 4103,\n",
       " 'indicates': 3250,\n",
       " 'credit': 1470,\n",
       " 'fm': 2504,\n",
       " 'prev': 4954,\n",
       " 'cxl': 1543,\n",
       " 'tix': 6525,\n",
       " 'online': 4477,\n",
       " 'rep': 5322,\n",
       " 'called': 912,\n",
       " 'quoted': 5110,\n",
       " 'higher': 2999,\n",
       " 'website': 7057,\n",
       " 'sna': 5926,\n",
       " 'mke': 4113,\n",
       " 'ord': 4509,\n",
       " 'weepysweetmonty': 7065,\n",
       " 'youre': 7275,\n",
       " 'planning': 4801,\n",
       " 'letting': 3685,\n",
       " 'overhead': 4564,\n",
       " 'compartment': 1257,\n",
       " 'asap': 387,\n",
       " 'yyz': 7290,\n",
       " 'issue': 3387,\n",
       " 'cleared': 1148,\n",
       " 'beautifully': 596,\n",
       " 'check': 1063,\n",
       " 'aa': 0,\n",
       " 'supervisor': 6235,\n",
       " 'emplid': 2060,\n",
       " 'allowed': 197,\n",
       " 'sj': 5862,\n",
       " 'final': 2392,\n",
       " 'boarding': 728,\n",
       " 'know': 3574,\n",
       " 'ala': 166,\n",
       " 'live': 3744,\n",
       " 'far': 2312,\n",
       " 'max': 3954,\n",
       " 'pulling': 5063,\n",
       " 'runway': 5529,\n",
       " 'making': 3889,\n",
       " 'mate': 3947,\n",
       " 'response': 5384,\n",
       " 'cb': 988,\n",
       " 'hello': 2966,\n",
       " 'four': 2555,\n",
       " 'since': 5838,\n",
       " 'landed': 3611,\n",
       " 'phx': 4755,\n",
       " 'tarmac': 6343,\n",
       " 'plus': 4839,\n",
       " 'report': 5336,\n",
       " 'baggage': 537,\n",
       " 'claim': 1128,\n",
       " 'leaf': 3653,\n",
       " 'midnight': 4048,\n",
       " 'charged': 1040,\n",
       " 'say': 5592,\n",
       " 'oh': 4448,\n",
       " 'ridiculous': 5440,\n",
       " 'preferred': 4926,\n",
       " 'mechanical': 3982,\n",
       " 'occurred': 4428,\n",
       " 'houston': 3094,\n",
       " 'earlier': 1969,\n",
       " 'hope': 3063,\n",
       " 'iad': 3133,\n",
       " 'helping': 2972,\n",
       " 'different': 1751,\n",
       " 'story': 6148,\n",
       " 'nope': 4345,\n",
       " 'apparently': 314,\n",
       " 'way': 7041,\n",
       " 'guess': 2844,\n",
       " 'southwest': 6000,\n",
       " 'lax': 3644,\n",
       " 'travel': 6618,\n",
       " 'friendly': 2593,\n",
       " 'nomorevirgin': 4326,\n",
       " 'bravo': 790,\n",
       " 'handling': 2880,\n",
       " 'msp': 4172,\n",
       " 'missed': 4094,\n",
       " 'surprise': 6255,\n",
       " 'bday': 582,\n",
       " 'reason': 5179,\n",
       " 'crashed': 1455,\n",
       " 'update': 6839,\n",
       " 'moving': 4164,\n",
       " 'usair': 6862,\n",
       " 'idiot': 3151,\n",
       " 'amp': 247,\n",
       " 'gave': 2678,\n",
       " 'else': 2036,\n",
       " 'fudgers': 2626,\n",
       " 'philly': 4743,\n",
       " 'orlando': 4524,\n",
       " 'truly': 6658,\n",
       " 'break': 793,\n",
       " 'unitedbreaksguitars': 6789,\n",
       " 'wantmymoneyback': 7020,\n",
       " 'outstanding': 4553,\n",
       " 'moved': 4161,\n",
       " 'mountain': 4156,\n",
       " 'francisco': 2563,\n",
       " 'waited': 6992,\n",
       " 'stuffy': 6187,\n",
       " 'americanairlines': 235,\n",
       " 'frustrated': 2613,\n",
       " 'seems': 5678,\n",
       " 'concerned': 1291,\n",
       " 'cousin': 1430,\n",
       " 'pdx': 4689,\n",
       " 'hire': 3013,\n",
       " 'sitter': 5854,\n",
       " 'til': 6505,\n",
       " 'arrives': 378,\n",
       " 'thx': 6490,\n",
       " 'keepitup': 3534,\n",
       " 'bird': 670,\n",
       " 'warmer': 7023,\n",
       " 'statement': 6097,\n",
       " 'lufthansa': 3842,\n",
       " 'incentive': 3217,\n",
       " 'offer': 4438,\n",
       " 'digital': 1757,\n",
       " 'journal': 3495,\n",
       " 'nashville': 4215,\n",
       " 'kidding': 3545,\n",
       " 'military': 4065,\n",
       " 'folk': 2511,\n",
       " 'cold': 1202,\n",
       " 'stlouis': 6132,\n",
       " 'enjoyed': 2088,\n",
       " 'asking': 399,\n",
       " 'kid': 3544,\n",
       " 'address': 86,\n",
       " 'tb': 6352,\n",
       " 'acct': 54,\n",
       " 'true': 6656,\n",
       " 'fuck': 2620,\n",
       " 'locator': 3770,\n",
       " 'aurorabiz': 457,\n",
       " 'phlairport': 4746,\n",
       " 'handler': 2879,\n",
       " 'broke': 824,\n",
       " 'suitcase': 6215,\n",
       " 'stole': 6138,\n",
       " 'camera': 917,\n",
       " 'returned': 5412,\n",
       " 'trash': 6617,\n",
       " 'american': 233,\n",
       " 'desk': 1703,\n",
       " 'queuing': 5099,\n",
       " 'headphone': 2941,\n",
       " 'jack': 3407,\n",
       " 'working': 7182,\n",
       " 'trip': 6641,\n",
       " 'epic': 2115,\n",
       " 'inconvenience': 3232,\n",
       " 'anku': 271,\n",
       " 'nonexistent': 4331,\n",
       " 'apparent': 313,\n",
       " 'remote': 5307,\n",
       " 'outpost': 4547,\n",
       " 'busy': 877,\n",
       " 'airport': 155,\n",
       " 'city': 1125,\n",
       " 'ok': 4454,\n",
       " 'registration': 5261,\n",
       " 'team': 6359,\n",
       " 'system': 6306,\n",
       " 'failure': 2294,\n",
       " 'last': 3624,\n",
       " 'week': 7061,\n",
       " 'currently': 1513,\n",
       " 'ogg': 4447,\n",
       " 'jlhalldc': 3475,\n",
       " 'relation': 5278,\n",
       " 'review': 5423,\n",
       " 'concern': 1290,\n",
       " 'contact': 1348,\n",
       " 'directly': 1772,\n",
       " 'john': 3482,\n",
       " 'bereavement': 629,\n",
       " 'discount': 1797,\n",
       " 'airfare': 149,\n",
       " 'grandfather': 2791,\n",
       " 'passed': 4647,\n",
       " 'attend': 440,\n",
       " 'glad': 2730,\n",
       " 'ive': 3403,\n",
       " 'transferred': 6606,\n",
       " 'without': 7151,\n",
       " 'resolving': 5375,\n",
       " 'imaginedragons': 3180,\n",
       " 'beatsmusic': 594,\n",
       " 'timed': 6511,\n",
       " 'tweet': 6692,\n",
       " 'boarded': 727,\n",
       " 'cll': 1159,\n",
       " 'let': 3679,\n",
       " 'importantflight': 3196,\n",
       " 'try': 6664,\n",
       " 'happens': 2892,\n",
       " 'allrepresentativesbusy': 200,\n",
       " 'nooption': 4344,\n",
       " 'entire': 2104,\n",
       " 'process': 4994,\n",
       " 'sooooo': 5980,\n",
       " 'long': 3791,\n",
       " 'decent': 1611,\n",
       " 'customerservice': 1528,\n",
       " 'getting': 2709,\n",
       " 'paradise': 4620,\n",
       " 'safely': 5547,\n",
       " 'explain': 2249,\n",
       " 'eager': 1966,\n",
       " 'ask': 396,\n",
       " 'vision': 6969,\n",
       " 'ccicanine': 994,\n",
       " 'guide': 2848,\n",
       " 'dog': 1867,\n",
       " 'baby': 510,\n",
       " 'hannah': 2887,\n",
       " 'life': 3697,\n",
       " 'saving': 5589,\n",
       " 'surgery': 6252,\n",
       " 'plz': 4840,\n",
       " 'bring': 813,\n",
       " 'cstmr': 1496,\n",
       " 'srvc': 6069,\n",
       " 'ctr': 1500,\n",
       " 'start': 6088,\n",
       " 'mine': 4071,\n",
       " 'actual': 71,\n",
       " 'person': 4721,\n",
       " 'dispute': 1825,\n",
       " 'charge': 1039,\n",
       " 'card': 943,\n",
       " 'best': 634,\n",
       " 'requesting': 5346,\n",
       " 're': 5153,\n",
       " 'kicked': 3542,\n",
       " 'entirely': 2105,\n",
       " 'unhelpful': 6777,\n",
       " 'wasting': 7032,\n",
       " 'idea': 3147,\n",
       " 'actually': 72,\n",
       " 'yall': 7242,\n",
       " 'right': 5444,\n",
       " 'past': 4656,\n",
       " 'tense': 6384,\n",
       " 'miserable': 4084,\n",
       " 'usual': 6886,\n",
       " 'clt': 1171,\n",
       " 'continue': 1361,\n",
       " 'impress': 3198,\n",
       " 'mco': 3966,\n",
       " 'professional': 5000,\n",
       " 'ouch': 4537,\n",
       " 'due': 1946,\n",
       " 'qro': 5087,\n",
       " 'seem': 5676,\n",
       " 'falling': 2302,\n",
       " 'apart': 306,\n",
       " 'alwaysdelayed': 219,\n",
       " 'unitedfail': 6790,\n",
       " 'row': 5500,\n",
       " 'cc': 993,\n",
       " 'everytime': 2173,\n",
       " 'returning': 5413,\n",
       " 'provide': 5038,\n",
       " 'information': 3277,\n",
       " 'instruction': 3315,\n",
       " 'pas': 4641,\n",
       " 'amsterdam': 248,\n",
       " 'jet': 3444,\n",
       " 'gotcha': 2777,\n",
       " 'correlate': 1397,\n",
       " 'flightd': 2448,\n",
       " 'chance': 1027,\n",
       " 'replacement': 5331,\n",
       " 'case': 968,\n",
       " 'cost': 1401,\n",
       " 'le': 3650,\n",
       " 'rather': 5147,\n",
       " 'forced': 2525,\n",
       " 'sit': 5850,\n",
       " 'push': 5075,\n",
       " 'hi': 2993,\n",
       " 'booked': 742,\n",
       " 'add': 79,\n",
       " 'leaving': 3662,\n",
       " 'warning': 7026,\n",
       " 'communication': 1247,\n",
       " 'shitty': 5773,\n",
       " 'space': 6009,\n",
       " 'empty': 2064,\n",
       " 'ffl': 2367,\n",
       " 'message': 4024,\n",
       " 'international': 3345,\n",
       " 'road': 5463,\n",
       " 'condition': 1296,\n",
       " 'horrible': 3072,\n",
       " 'told': 6545,\n",
       " 'loyalty': 3832,\n",
       " 'basically': 570,\n",
       " 'flipped': 2469,\n",
       " 'google': 2772,\n",
       " 'refused': 5254,\n",
       " 'despite': 1708,\n",
       " 'neveragain': 4260,\n",
       " 'dropped': 1932,\n",
       " 'layover': 3646,\n",
       " 'lack': 3597,\n",
       " 'shined': 5766,\n",
       " 'step': 6114,\n",
       " 'return': 5411,\n",
       " 'aware': 492,\n",
       " 'premier': 4934,\n",
       " 'access': 35,\n",
       " 'closed': 1162,\n",
       " 'terminal': 6388,\n",
       " 'feel': 2352,\n",
       " 'following': 2516,\n",
       " 'worstcustomerservice': 7192,\n",
       " 'guc': 2843,\n",
       " 'suck': 6204,\n",
       " 'pushed': 5077,\n",
       " 'rude': 5514,\n",
       " 'pt': 5053,\n",
       " 'helpful': 2970,\n",
       " 'thing': 6454,\n",
       " 'high': 2998,\n",
       " 'surely': 6248,\n",
       " 'something': 5968,\n",
       " 'join': 3484,\n",
       " 'site': 5851,\n",
       " 'app': 311,\n",
       " 'favorite': 2333,\n",
       " 'adding': 81,\n",
       " 'columbus': 1217,\n",
       " 'oakland': 4416,\n",
       " 'bostonlogan': 758,\n",
       " 'dispatchalerts': 1818,\n",
       " 'fucking': 2625,\n",
       " 'human': 3112,\n",
       " 'disconnection': 1795,\n",
       " 'excuse': 2206,\n",
       " 'sweetheart': 6281,\n",
       " 'screwed': 5637,\n",
       " 'flyfrontier': 2488,\n",
       " 'managed': 3898,\n",
       " 'scramble': 5629,\n",
       " 'calling': 914,\n",
       " 'misplaced': 4092,\n",
       " 'disaster': 1788,\n",
       " 'board': 726,\n",
       " 'airway': 162,\n",
       " 'double': 1892,\n",
       " 'twice': 6698,\n",
       " 'den': 1662,\n",
       " 'mpagent': 4165,\n",
       " 'seanmfmadden': 5646,\n",
       " 'peterstraubmma': 4729,\n",
       " 'jmercadomma': 3477,\n",
       " 'tonysimsmma': 6560,\n",
       " 'vega': 6921,\n",
       " 'nonstop': 4335,\n",
       " 'big': 661,\n",
       " 'guest': 2846,\n",
       " 'require': 5347,\n",
       " 'btw': 838,\n",
       " 'sayin': 5593,\n",
       " 'particularly': 4634,\n",
       " 'poorly': 4864,\n",
       " 'handled': 2878,\n",
       " 'situation': 5856,\n",
       " 'crazy': 1461,\n",
       " 'run': 5526,\n",
       " 'piece': 4767,\n",
       " 'ruining': 5521,\n",
       " 'ha': 2858,\n",
       " 'fun': 2634,\n",
       " 'full': 2632,\n",
       " 'pay': 4678,\n",
       " 'forth': 2546,\n",
       " 'moodlighting': 4143,\n",
       " 'cool': 1382,\n",
       " 'calming': 915,\n",
       " 'moodlitmonday': 4144,\n",
       " 'literally': 3742,\n",
       " 'retrieve': 5408,\n",
       " 'save': 5585,\n",
       " 'visit': 6970,\n",
       " 'impact': 3188,\n",
       " 'mother': 4153,\n",
       " 'planned': 4799,\n",
       " 'rule': 5522,\n",
       " 'ice': 3136,\n",
       " 'using': 6884,\n",
       " 'cell': 1003,\n",
       " 'flashlight': 2426,\n",
       " 'come': 1225,\n",
       " 'error': 2134,\n",
       " 'purchase': 5069,\n",
       " 'least': 3658,\n",
       " 'cavalli': 985,\n",
       " 'calf': 906,\n",
       " 'interfering': 3340,\n",
       " 'onboard': 4467,\n",
       " 'equipment': 2126,\n",
       " 'possible': 4882,\n",
       " 'seeing': 5673,\n",
       " 'sunset': 6228,\n",
       " 'usvi': 6889,\n",
       " 'jal': 3416,\n",
       " 'cathay': 979,\n",
       " 'pacific': 4585,\n",
       " 'likingyoulessandless': 3714,\n",
       " 'causing': 984,\n",
       " 'inferior': 3266,\n",
       " 'nationalized': 4222,\n",
       " 'third': 6459,\n",
       " 'world': 7184,\n",
       " 'nation': 4220,\n",
       " 'pm': 4841,\n",
       " 'sent': 5704,\n",
       " 'rdu': 5152,\n",
       " 'think': 6457,\n",
       " 'safety': 5549,\n",
       " 'cant': 930,\n",
       " 'memphis': 4011,\n",
       " 'coming': 1235,\n",
       " 'finger': 2403,\n",
       " 'crossed': 1480,\n",
       " 'submitted': 6196,\n",
       " 'hoping': 3069,\n",
       " 'quick': 5100,\n",
       " 'decision': 1615,\n",
       " 'tied': 6501,\n",
       " 'donation': 1877,\n",
       " 'annual': 283,\n",
       " 'gala': 2665,\n",
       " 'boundless': 770,\n",
       " 'reader': 5164,\n",
       " 'feedback': 2351,\n",
       " 'benefit': 625,\n",
       " 'atrocious': 433,\n",
       " 'already': 207,\n",
       " 'technical': 6365,\n",
       " 'send': 5695,\n",
       " 'screen': 5633,\n",
       " 'shot': 5790,\n",
       " 'question': 5097,\n",
       " 'procedure': 4991,\n",
       " 'confusion': 1312,\n",
       " 'prevent': 4955,\n",
       " 'fistfight': 2415,\n",
       " 'contaced': 1347,\n",
       " 'eyewitness': 2273,\n",
       " 'news': 4272,\n",
       " 'ripoff': 5449,\n",
       " 'dpdfpp': 1906,\n",
       " 'dealing': 1599,\n",
       " 'crappy': 1453,\n",
       " 'web': 7053,\n",
       " 'form': 2539,\n",
       " 'mobile': 4118,\n",
       " 'device': 1727,\n",
       " 'roc': 5475,\n",
       " 'fam': 2306,\n",
       " 'came': 916,\n",
       " 'member': 4005,\n",
       " 'dad': 1550,\n",
       " 'used': 6879,\n",
       " 'input': 3296,\n",
       " 'duecto': 1947,\n",
       " 'engine': 2083,\n",
       " 'trouble': 6648,\n",
       " 'willl': 7128,\n",
       " 'argentina': 359,\n",
       " 'whole': 7112,\n",
       " 'rocked': 5477,\n",
       " 'diversion': 1843,\n",
       " 'keeping': 3531,\n",
       " 'informed': 3279,\n",
       " 'finally': 2394,\n",
       " 'opening': 4493,\n",
       " 'conversation': 1373,\n",
       " 'disconnect': 1792,\n",
       " 'stay': 6103,\n",
       " 'checkout': 1068,\n",
       " 'place': 4791,\n",
       " 'able': 18,\n",
       " 'interim': 3341,\n",
       " 'expense': 2239,\n",
       " 'stuff': 6186,\n",
       " 'playing': 4812,\n",
       " 'va': 6898,\n",
       " 'citizen': 1124,\n",
       " 'constantly': 1340,\n",
       " 'offended': 4435,\n",
       " 'derrick': 1688,\n",
       " 'bussey': 876,\n",
       " 'cry': 1489,\n",
       " 'upset': 6853,\n",
       " 'jt': 3503,\n",
       " 'eventually': 2166,\n",
       " 'completely': 1277,\n",
       " 'unacceptable': 6727,\n",
       " 'chicago': 1079,\n",
       " 'lose': 3804,\n",
       " 'caught': 981,\n",
       " 'original': 4520,\n",
       " 'land': 3610,\n",
       " 'mel': 4000,\n",
       " 'sticker': 6122,\n",
       " 'clue': 1174,\n",
       " 'confirming': 1306,\n",
       " 'arranged': 373,\n",
       " 'expedite': 2235,\n",
       " 'answer': 286,\n",
       " 'care': 945,\n",
       " 'better': 645,\n",
       " 'chairman': 1020,\n",
       " 'connect': 1317,\n",
       " 'sjc': 5863,\n",
       " 'reroute': 5352,\n",
       " 'global': 2737,\n",
       " 'lounge': 3818,\n",
       " 'menu': 4017,\n",
       " 'yummy': 7285,\n",
       " 'overbooked': 4557,\n",
       " 'mia': 4038,\n",
       " 'uvf': 6895,\n",
       " 'economy': 2002,\n",
       " 'special': 6021,\n",
       " 'fligt': 2467,\n",
       " 'status': 6101,\n",
       " 'sunrise': 6226,\n",
       " 'frankly': 2565,\n",
       " 'standard': 6081,\n",
       " 'sop': 5983,\n",
       " 'boston': 757,\n",
       " 'relate': 5277,\n",
       " 'connecting': 1320,\n",
       " 'gassing': 2674,\n",
       " 'communicated': 1246,\n",
       " 'point': 4847,\n",
       " 'silence': 5825,\n",
       " 'sat': 5577,\n",
       " 'broken': 825,\n",
       " 'joke': 3486,\n",
       " 'confused': 1310,\n",
       " 'definition': 1632,\n",
       " 'extra': 2264,\n",
       " 'regular': 5264,\n",
       " 'legroom': 3672,\n",
       " 'unimpressed': 6780,\n",
       " 'phl': 4745,\n",
       " 'nowhere': 4390,\n",
       " 'accurate': 57,\n",
       " 'group': 2827,\n",
       " 'frm': 2600,\n",
       " 'food': 2519,\n",
       " 'comp': 1251,\n",
       " 'additional': 83,\n",
       " 'dollar': 1871,\n",
       " 'hole': 3034,\n",
       " 'however': 3096,\n",
       " 'failed': 2288,\n",
       " 'solution': 5959,\n",
       " 'straight': 6152,\n",
       " 'happen': 2889,\n",
       " 'cruise': 1485,\n",
       " 'claimed': 1129,\n",
       " 'exact': 2186,\n",
       " 'explained': 2250,\n",
       " 'reopens': 5321,\n",
       " 'divert': 1844,\n",
       " 'closer': 1164,\n",
       " 'acy': 74,\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2022-11-22-02-17-27.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_tf_idf = tf_idf_vectorizer.fit_transform(X_train)   # When we say fit, it first determines whether it is passed in each line and then the number of passes in each document.\n",
    "X_test_tf_idf = tf_idf_vectorizer.transform(X_test)     # Applies the TF-IDF Formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaaand', 'aaadvantage', ..., 'zrh', 'zukes', 'zurich'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf_idf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaadvantage</th>\n",
       "      <th>aaalwayslate</th>\n",
       "      <th>aacustomerservice</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>aafail</th>\n",
       "      <th>aaron</th>\n",
       "      <th>...</th>\n",
       "      <th>yyz</th>\n",
       "      <th>zabsonre</th>\n",
       "      <th>zambia</th>\n",
       "      <th>zero</th>\n",
       "      <th>zfv</th>\n",
       "      <th>zkatcher</th>\n",
       "      <th>zone</th>\n",
       "      <th>zrh</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7320 rows × 7300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaaand  aaadvantage  aaalwayslate  aacustomerservice  aadavantage  \\\n",
       "0     0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "1     0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "2     0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "3     0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "4     0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "...   ...     ...          ...           ...                ...          ...   \n",
       "7315  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "7316  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "7317  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "7318  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "7319  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "\n",
       "      aadv  aadvantage  aafail  aaron  ...  yyz  zabsonre  zambia  zero  zfv  \\\n",
       "0      0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "1      0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "2      0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "3      0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "4      0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "...    ...         ...     ...    ...  ...  ...       ...     ...   ...  ...   \n",
       "7315   0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "7316   0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "7317   0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "7318   0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "7319   0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "\n",
       "      zkatcher  zone  zrh  zukes  zurich  \n",
       "0          0.0   0.0  0.0    0.0     0.0  \n",
       "1          0.0   0.0  0.0    0.0     0.0  \n",
       "2          0.0   0.0  0.0    0.0     0.0  \n",
       "3          0.0   0.0  0.0    0.0     0.0  \n",
       "4          0.0   0.0  0.0    0.0     0.0  \n",
       "...        ...   ...  ...    ...     ...  \n",
       "7315       0.0   0.0  0.0    0.0     0.0  \n",
       "7316       0.0   0.0  0.0    0.0     0.0  \n",
       "7317       0.0   0.0  0.0    0.0     0.0  \n",
       "7318       0.0   0.0  0.0    0.0     0.0  \n",
       "7319       0.0   0.0  0.0    0.0     0.0  \n",
       "\n",
       "[7320 rows x 7300 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(X_train_tf_idf.toarray(), columns = tf_idf_vectorizer.get_feature_names_out())\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica seriously would pay flight seat playing really bad thing flying va'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bit         0.565101\n",
       "follow      0.449861\n",
       "yes         0.401677\n",
       "dm          0.397842\n",
       "ca          0.341823\n",
       "              ...   \n",
       "fleek       0.000000\n",
       "flawless    0.000000\n",
       "flaw        0.000000\n",
       "flavor      0.000000\n",
       "zurich      0.000000\n",
       "Name: 2, Length: 7300, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf.loc[2].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'virginamerica really aggressive blast obnoxious entertainment guest face amp little recourse'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaadvantage</th>\n",
       "      <th>aaalwayslate</th>\n",
       "      <th>aacustomerservice</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>aafail</th>\n",
       "      <th>aaron</th>\n",
       "      <th>...</th>\n",
       "      <th>yyz</th>\n",
       "      <th>zabsonre</th>\n",
       "      <th>zambia</th>\n",
       "      <th>zero</th>\n",
       "      <th>zfv</th>\n",
       "      <th>zkatcher</th>\n",
       "      <th>zone</th>\n",
       "      <th>zrh</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7316</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7318</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7319</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7320 rows × 7300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaaand  aaadvantage  aaalwayslate  aacustomerservice  aadavantage  \\\n",
       "0     0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "1     0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "2     0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "3     0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "4     0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "...   ...     ...          ...           ...                ...          ...   \n",
       "7315  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "7316  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "7317  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "7318  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "7319  0.0     0.0          0.0           0.0                0.0          0.0   \n",
       "\n",
       "      aadv  aadvantage  aafail  aaron  ...  yyz  zabsonre  zambia  zero  zfv  \\\n",
       "0      0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "1      0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "2      0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "3      0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "4      0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "...    ...         ...     ...    ...  ...  ...       ...     ...   ...  ...   \n",
       "7315   0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "7316   0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "7317   0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "7318   0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "7319   0.0         0.0     0.0    0.0  ...  0.0       0.0     0.0   0.0  0.0   \n",
       "\n",
       "      zkatcher  zone  zrh  zukes  zurich  \n",
       "0          0.0   0.0  0.0    0.0     0.0  \n",
       "1          0.0   0.0  0.0    0.0     0.0  \n",
       "2          0.0   0.0  0.0    0.0     0.0  \n",
       "3          0.0   0.0  0.0    0.0     0.0  \n",
       "4          0.0   0.0  0.0    0.0     0.0  \n",
       "...        ...   ...  ...    ...     ...  \n",
       "7315       0.0   0.0  0.0    0.0     0.0  \n",
       "7316       0.0   0.0  0.0    0.0     0.0  \n",
       "7317       0.0   0.0  0.0    0.0     0.0  \n",
       "7318       0.0   0.0  0.0    0.0     0.0  \n",
       "7319       0.0   0.0  0.0    0.0     0.0  \n",
       "\n",
       "[7320 rows x 7300 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(X_train_tf_idf.toarray(), columns = tf_idf_vectorizer.get_feature_names_out())\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d8cd8638caa719e77c3ece9ee6c9cdab6f2065d170551d375a17b4273bc3a23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
